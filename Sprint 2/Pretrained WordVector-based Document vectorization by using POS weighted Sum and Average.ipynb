{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbb084bf",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e8e453",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35511/1246376763.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy as cp\n",
    "import spacy\n",
    "import gensim.downloader\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cd3b12",
   "metadata": {},
   "source": [
    "## Model importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a152aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show all available models in gensim-data\n",
    "\n",
    "print(\"Models:\")\n",
    "print(list(gensim.downloader.info()['models'].keys()),\"\\n\")\n",
    "\n",
    "model = gensim.downloader.load('glove-twitter-25')\n",
    "# model.save(\"word2vec.model\")\n",
    "\n",
    "# print(\"Model download:\")\n",
    "# model = gensim.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a583615",
   "metadata": {},
   "source": [
    "## Bases importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b62979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qa_base = pd.read_csv('./insurance_qna_dataset.csv',sep='\\t',index_col=0)\n",
    "questions_number = qa_base.shape[0]\n",
    "\n",
    "qm_base = pd.read_csv(\"Test questions dataset.csv\")\n",
    "test_questions_number = qm_base.shape[0]\n",
    "\n",
    "# qa_base.head()\n",
    "qm_base.head(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bc336c",
   "metadata": {},
   "source": [
    "## Words tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c48480",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_base_tokenized = []\n",
    "    \n",
    "for i in range(questions_number):\n",
    "    sentence = qa_base[\"Question\"][i]\n",
    "    token_words = word_tokenize(sentence)\n",
    "    if token_words[-1] == '?':\n",
    "        token_words.pop()\n",
    "    token_words_lower = [word.lower() for word in token_words]\n",
    "    qa_base_tokenized.append(token_words_lower)\n",
    "\n",
    "oq_tokenized = []\n",
    "qlm_tokenized = []\n",
    "qmm_tokenized = []\n",
    "qhm_tokenized = []\n",
    "\n",
    "for i in range(test_questions_number):\n",
    "    original_question = qm_base[\"original question\"][i]\n",
    "    light_modified_question = qm_base[\"modified question – light\"][i]\n",
    "    medium_modified_question = qm_base[\"modified question – medium\"][i]\n",
    "    heavy_modified_question = qm_base[\"modified question – heavy\"][i]\n",
    "    \n",
    "    token_words_oq = word_tokenize(original_question)\n",
    "    token_words_qlm = word_tokenize(light_modified_question)\n",
    "    token_words_qmm = word_tokenize(medium_modified_question)\n",
    "    token_words_qhm = word_tokenize(heavy_modified_question)\n",
    "    \n",
    "    token_words_oq.pop()\n",
    "    token_words_qlm.pop()\n",
    "    token_words_qmm.pop()\n",
    "    token_words_qhm.pop()\n",
    "    \n",
    "    token_words_oq_lower = [word.lower() for word in token_words_oq]\n",
    "    token_words_qlm_lower = [word.lower() for word in token_words_qlm]\n",
    "    token_words_qmm_lower = [word.lower() for word in token_words_qmm]\n",
    "    token_words_qhm_lower = [word.lower() for word in token_words_qhm]\n",
    "    \n",
    "    oq_tokenized.append(token_words_oq_lower)\n",
    "    qlm_tokenized.append(token_words_qlm_lower)\n",
    "    qmm_tokenized.append(token_words_qmm_lower)\n",
    "    qhm_tokenized.append(token_words_qhm_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c84212d",
   "metadata": {},
   "source": [
    "## Words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e73a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def vectorizer(sentence):\n",
    "    vectorized_sentence = []\n",
    "    for i in range(len(sentence)):\n",
    "        try:\n",
    "            word = sentence[i]\n",
    "            word_vectorized = model[word].tolist()\n",
    "            word_spacy = nlp(word)\n",
    "            for token in word_spacy:     \n",
    "                pos = token.pos_\n",
    "                break\n",
    "            if pos == \"NOUN\" or pos == \"PROPN\" or pos == \"ADJ\":\n",
    "                pos_coef = 2\n",
    "            elif pos == \"VERB\":\n",
    "                pos_coef = 1\n",
    "            elif pos == \"NUM\":\n",
    "                pos_coef = 0\n",
    "            else:\n",
    "                pos_coef = 0.5\n",
    "            word_vectorized = [pos_coef*element for element in word_vectorized]\n",
    "            vectorized_sentence.append(word_vectorized)\n",
    "        except:\n",
    "            pass\n",
    "    return vectorized_sentence\n",
    "            \n",
    "\n",
    "def token_sum(sentence):\n",
    "    vector_length = len(sentence[0])\n",
    "    sum_list = []\n",
    "    for i in range(vector_length):\n",
    "        counter = 0\n",
    "        for word in sentence:\n",
    "            counter += word[i]\n",
    "        sum_list.append(counter)\n",
    "    return sum_list\n",
    "    \n",
    "def token_mean(sentence):\n",
    "    vector_length = len(sentence[0])\n",
    "    mean_list = []\n",
    "    for i in range(vector_length):\n",
    "        local_mean_list = []\n",
    "        for word in sentence:\n",
    "            local_mean_list.append(word[i])\n",
    "        mean_list.append(np.mean(local_mean_list))\n",
    "    return mean_list\n",
    "\n",
    "qa_base_vectorized_sum = []\n",
    "qa_base_vectorized_mean = []\n",
    "\n",
    "for i in range(questions_number):\n",
    "    sentence = vectorizer(qa_base_tokenized[i])\n",
    "    print(sentence)\n",
    "    sentence_sum = token_sum(sentence)\n",
    "    sentence_mean = token_mean(sentence)\n",
    "    qa_base_vectorized_sum.append(sentence_sum)\n",
    "    qa_base_vectorized_mean.append(sentence_mean)\n",
    "    \n",
    "    break\n",
    "    \n",
    "qlm_vectorized_sum = []\n",
    "qlm_vectorized_mean = []\n",
    "qmm_vectorized_sum = []\n",
    "qmm_vectorized_mean = []\n",
    "qhm_vectorized_sum = []\n",
    "qhm_vectorized_mean = []\n",
    "\n",
    "# for i in range(test_questions_number):\n",
    "#     qlm_sentence = vectorizer(qlm_tokenized[i])\n",
    "#     qmm_sentence = vectorizer(qmm_tokenized[i])\n",
    "#     qhm_sentence = vectorizer(qhm_tokenized[i])\n",
    "    \n",
    "#     qlm_sentence_sum = token_sum(qlm_sentence)\n",
    "#     qmm_sentence_sum = token_sum(qmm_sentence)\n",
    "#     qhm_sentence_sum = token_sum(qhm_sentence)\n",
    "    \n",
    "#     qlm_sentence_mean = token_mean(qlm_sentence)\n",
    "#     qmm_sentence_mean = token_mean(qmm_sentence)\n",
    "#     qhm_sentence_mean = token_mean(qhm_sentence)\n",
    "    \n",
    "#     qlm_vectorized_sum.append(qlm_sentence_sum)\n",
    "#     qmm_vectorized_sum.append(qmm_sentence_sum)\n",
    "#     qhm_vectorized_sum.append(qhm_sentence_sum)\n",
    "    \n",
    "#     qlm_vectorized_mean.append(qlm_sentence_mean)\n",
    "#     qmm_vectorized_mean.append(qmm_sentence_mean)\n",
    "#     qhm_vectorized_mean.append(qhm_sentence_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1824a58",
   "metadata": {},
   "source": [
    "## Nearest Neighbors space creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03707aff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nbrs_euclidean_sum = NearestNeighbors(n_neighbors=25000, metric=\"euclidean\").fit(qa_base_vectorized_sum)\n",
    "nbrs_manhattan_sum = NearestNeighbors(n_neighbors=25000, metric=\"manhattan\").fit(qa_base_vectorized_sum)\n",
    "nbrs_cosine_sum = NearestNeighbors(n_neighbors=25000, metric=\"cosine\").fit(qa_base_vectorized_sum)\n",
    "\n",
    "nbrs_euclidean_mean = NearestNeighbors(n_neighbors=25000, metric=\"euclidean\").fit(qa_base_vectorized_mean)\n",
    "nbrs_manhattan_mean = NearestNeighbors(n_neighbors=25000, metric=\"manhattan\").fit(qa_base_vectorized_mean)\n",
    "nbrs_cosine_mean = NearestNeighbors(n_neighbors=25000, metric=\"cosine\").fit(qa_base_vectorized_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e629d281",
   "metadata": {},
   "source": [
    "## Recording results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7da1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = ['arithmetics',\n",
    "                                  'questions modification',\n",
    "                                  'metric',\n",
    "                                  'average sentence rank',\n",
    "                                  'accuracy [%]',\n",
    "                                  'average execution time [s]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b3c37",
   "metadata": {},
   "source": [
    "## Lightly modified questions - sum arithmetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d01cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "euclidean_ranks = []\n",
    "manhattan_ranks = []\n",
    "cos_ranks = []\n",
    "\n",
    "euclidean_target_counter = 0\n",
    "manhattan_target_counter = 0\n",
    "cos_target_counter = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(test_questions_number):\n",
    "    \n",
    "    original_question = qm_base[\"original question\"][i]\n",
    "    modified_question = np.reshape(qlm_vectorized_sum[i],(1,-1))\n",
    "    \n",
    "    distances_euclidean, indices_euclidean = nbrs_euclidean_sum.kneighbors(modified_question)\n",
    "    distances_manhattan, indices_manhattan = nbrs_manhattan_sum.kneighbors(modified_question)\n",
    "    distances_cosine, indices_cosine = nbrs_cosine_sum.kneighbors(modified_question)\n",
    "    \n",
    "    nbrs_list_euclidean = qa_base[\"Question\"].iloc[indices_euclidean[0]].tolist()\n",
    "    nbrs_list_manhattan = qa_base[\"Question\"].iloc[indices_manhattan[0]].tolist()\n",
    "    nbrs_list_cosine = qa_base[\"Question\"].iloc[indices_cosine[0]].tolist()\n",
    "    \n",
    "    euclidean_rank = nbrs_list_euclidean.index(original_question)+1\n",
    "    manhattan_rank = nbrs_list_manhattan.index(original_question)+1\n",
    "    cos_rank = nbrs_list_cosine.index(original_question)+1\n",
    "    \n",
    "    euclidean_ranks.append(euclidean_rank)\n",
    "    manhattan_ranks.append(manhattan_rank)\n",
    "    cos_ranks.append(cos_rank)\n",
    "    \n",
    "    if euclidean_rank <= 300:\n",
    "        euclidean_target_counter += 1\n",
    "    if manhattan_rank <= 300:\n",
    "        manhattan_target_counter += 1\n",
    "    if cos_rank <= 300:\n",
    "        cos_target_counter += 1\n",
    "    \n",
    "end = time.time()\n",
    "t = (end-start)/test_questions_number\n",
    "\n",
    "print(\"Light modifications - euclidian ranks:\", euclidean_ranks)\n",
    "print(\"Light modifications - manhattan ranks:\", manhattan_ranks)\n",
    "print(\"Light modifications - cos ranks:\", cos_ranks)\n",
    "\n",
    "data = {'arithmetics':'sum',\n",
    "         'questions modification':'light',\n",
    "         'metric':'euclidean',\n",
    "         'average sentence rank':round(np.mean(euclidean_rank)),\n",
    "         'accuracy [%]':round((euclidean_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)\n",
    "\n",
    "data = {'arithmetics':'sum',\n",
    "         'questions modification':'light',\n",
    "         'metric':'manhattan',\n",
    "         'average sentence rank':round(np.mean(manhattan_rank)),\n",
    "         'accuracy [%]':round((manhattan_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)\n",
    "\n",
    "data = {'arithmetics':'sum',\n",
    "         'questions modification':'light',\n",
    "         'metric':'cosine',\n",
    "         'average sentence rank':round(np.mean(cos_rank)),\n",
    "         'accuracy [%]':round((cos_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8be5e4",
   "metadata": {},
   "source": [
    "## Lightly modified questions - mean arithmetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4783b0ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "euclidean_ranks = []\n",
    "manhattan_ranks = []\n",
    "cos_ranks = []\n",
    "\n",
    "euclidean_target_counter = 0\n",
    "manhattan_target_counter = 0\n",
    "cos_target_counter = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(test_questions_number):\n",
    "    \n",
    "    original_question = qm_base[\"original question\"][i]\n",
    "    modified_question = np.reshape(qlm_vectorized_mean[i],(1,-1))\n",
    "    \n",
    "    distances_euclidean, indices_euclidean = nbrs_euclidean_mean.kneighbors(modified_question)\n",
    "    distances_manhattan, indices_manhattan = nbrs_manhattan_mean.kneighbors(modified_question)\n",
    "    distances_cosine, indices_cosine = nbrs_cosine_mean.kneighbors(modified_question)\n",
    "    \n",
    "    nbrs_list_euclidean = qa_base[\"Question\"].iloc[indices_euclidean[0]].tolist()\n",
    "    nbrs_list_manhattan = qa_base[\"Question\"].iloc[indices_manhattan[0]].tolist()\n",
    "    nbrs_list_cosine = qa_base[\"Question\"].iloc[indices_cosine[0]].tolist()\n",
    "    \n",
    "    euclidean_rank = nbrs_list_euclidean.index(original_question)+1\n",
    "    manhattan_rank = nbrs_list_manhattan.index(original_question)+1\n",
    "    cos_rank = nbrs_list_cosine.index(original_question)+1\n",
    "    \n",
    "    euclidean_ranks.append(euclidean_rank)\n",
    "    manhattan_ranks.append(manhattan_rank)\n",
    "    cos_ranks.append(cos_rank)\n",
    "    \n",
    "    if euclidean_rank <= 300:\n",
    "        euclidean_target_counter += 1\n",
    "    if manhattan_rank <= 300:\n",
    "        manhattan_target_counter += 1\n",
    "    if cos_rank <= 300:\n",
    "        cos_target_counter += 1\n",
    "    \n",
    "end = time.time()\n",
    "t = (end-start)/test_questions_number\n",
    "\n",
    "print(\"Light modifications - euclidian ranks:\", euclidean_ranks)\n",
    "print(\"Light modifications - manhattan ranks:\", manhattan_ranks)\n",
    "print(\"Light modifications - cos ranks:\", cos_ranks)\n",
    "\n",
    "data = {'arithmetics':'mean',\n",
    "         'questions modification':'light',\n",
    "         'metric':'euclidean',\n",
    "         'average sentence rank':round(np.mean(euclidean_rank)),\n",
    "         'accuracy [%]':round((euclidean_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)\n",
    "\n",
    "data = {'arithmetics':'mean',\n",
    "         'questions modification':'light',\n",
    "         'metric':'manhattan',\n",
    "         'average sentence rank':round(np.mean(manhattan_rank)),\n",
    "         'accuracy [%]':round((manhattan_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)\n",
    "\n",
    "data = {'arithmetics':'mean',\n",
    "         'questions modification':'light',\n",
    "         'metric':'cosine',\n",
    "         'average sentence rank':round(np.mean(cos_rank)),\n",
    "         'accuracy [%]':round((cos_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0cfb61",
   "metadata": {},
   "source": [
    "## Medium modified questions - sum arithmetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a25b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "euclidean_ranks = []\n",
    "manhattan_ranks = []\n",
    "cos_ranks = []\n",
    "\n",
    "euclidean_target_counter = 0\n",
    "manhattan_target_counter = 0\n",
    "cos_target_counter = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(test_questions_number):\n",
    "    \n",
    "    original_question = qm_base[\"original question\"][i]\n",
    "    modified_question = np.reshape(qmm_vectorized_sum[i],(1,-1))\n",
    "    \n",
    "    distances_euclidean, indices_euclidean = nbrs_euclidean_sum.kneighbors(modified_question)\n",
    "    distances_manhattan, indices_manhattan = nbrs_manhattan_sum.kneighbors(modified_question)\n",
    "    distances_cosine, indices_cosine = nbrs_cosine_sum.kneighbors(modified_question)\n",
    "    \n",
    "    nbrs_list_euclidean = qa_base[\"Question\"].iloc[indices_euclidean[0]].tolist()\n",
    "    nbrs_list_manhattan = qa_base[\"Question\"].iloc[indices_manhattan[0]].tolist()\n",
    "    nbrs_list_cosine = qa_base[\"Question\"].iloc[indices_cosine[0]].tolist()\n",
    "    \n",
    "    euclidean_rank = nbrs_list_euclidean.index(original_question)+1\n",
    "    manhattan_rank = nbrs_list_manhattan.index(original_question)+1\n",
    "    cos_rank = nbrs_list_cosine.index(original_question)+1\n",
    "    \n",
    "    euclidean_ranks.append(euclidean_rank)\n",
    "    manhattan_ranks.append(manhattan_rank)\n",
    "    cos_ranks.append(cos_rank)\n",
    "    \n",
    "    if euclidean_rank <= 300:\n",
    "        euclidean_target_counter += 1\n",
    "    if manhattan_rank <= 300:\n",
    "        manhattan_target_counter += 1\n",
    "    if cos_rank <= 300:\n",
    "        cos_target_counter += 1\n",
    "    \n",
    "end = time.time()\n",
    "t = (end-start)/test_questions_number\n",
    "\n",
    "print(\"Medium modifications - euclidian ranks:\", euclidean_ranks)\n",
    "print(\"Medium modifications - manhattan ranks:\", manhattan_ranks)\n",
    "print(\"Medium modifications - cos ranks:\", cos_ranks)\n",
    "\n",
    "data = {'arithmetics':'sum',\n",
    "         'questions modification':'medium',\n",
    "         'metric':'euclidean',\n",
    "         'average sentence rank':round(np.mean(euclidean_rank)),\n",
    "         'accuracy [%]':round((euclidean_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)\n",
    "\n",
    "data = {'arithmetics':'sum',\n",
    "         'questions modification':'medium',\n",
    "         'metric':'manhattan',\n",
    "         'average sentence rank':round(np.mean(manhattan_rank)),\n",
    "         'accuracy [%]':round((manhattan_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)\n",
    "\n",
    "data = {'arithmetics':'sum',\n",
    "         'questions modification':'medium',\n",
    "         'metric':'cosine',\n",
    "         'average sentence rank':round(np.mean(cos_rank)),\n",
    "         'accuracy [%]':round((cos_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85e6ddd",
   "metadata": {},
   "source": [
    "## Medium modified questions - mean arithmetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc13bdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "euclidean_ranks = []\n",
    "manhattan_ranks = []\n",
    "cos_ranks = []\n",
    "\n",
    "euclidean_target_counter = 0\n",
    "manhattan_target_counter = 0\n",
    "cos_target_counter = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(test_questions_number):\n",
    "    \n",
    "    original_question = qm_base[\"original question\"][i]\n",
    "    modified_question = np.reshape(qmm_vectorized_mean[i],(1,-1))\n",
    "    \n",
    "    distances_euclidean, indices_euclidean = nbrs_euclidean_mean.kneighbors(modified_question)\n",
    "    distances_manhattan, indices_manhattan = nbrs_manhattan_mean.kneighbors(modified_question)\n",
    "    distances_cosine, indices_cosine = nbrs_cosine_mean.kneighbors(modified_question)\n",
    "    \n",
    "    nbrs_list_euclidean = qa_base[\"Question\"].iloc[indices_euclidean[0]].tolist()\n",
    "    nbrs_list_manhattan = qa_base[\"Question\"].iloc[indices_manhattan[0]].tolist()\n",
    "    nbrs_list_cosine = qa_base[\"Question\"].iloc[indices_cosine[0]].tolist()\n",
    "    \n",
    "    euclidean_rank = nbrs_list_euclidean.index(original_question)+1\n",
    "    manhattan_rank = nbrs_list_manhattan.index(original_question)+1\n",
    "    cos_rank = nbrs_list_cosine.index(original_question)+1\n",
    "    \n",
    "    euclidean_ranks.append(euclidean_rank)\n",
    "    manhattan_ranks.append(manhattan_rank)\n",
    "    cos_ranks.append(cos_rank)\n",
    "    \n",
    "    if euclidean_rank <= 300:\n",
    "        euclidean_target_counter += 1\n",
    "    if manhattan_rank <= 300:\n",
    "        manhattan_target_counter += 1\n",
    "    if cos_rank <= 300:\n",
    "        cos_target_counter += 1\n",
    "    \n",
    "end = time.time()\n",
    "t = (end-start)/test_questions_number\n",
    "\n",
    "print(\"Medium modifications - euclidian ranks:\", euclidean_ranks)\n",
    "print(\"Medium modifications - manhattan ranks:\", manhattan_ranks)\n",
    "print(\"Medium modifications - cos ranks:\", cos_ranks)\n",
    "\n",
    "data = {'arithmetics':'mean',\n",
    "         'questions modification':'medium',\n",
    "         'metric':'euclidean',\n",
    "         'average sentence rank':round(np.mean(euclidean_rank)),\n",
    "         'accuracy [%]':round((euclidean_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)\n",
    "\n",
    "data = {'arithmetics':'mean',\n",
    "         'questions modification':'medium',\n",
    "         'metric':'manhattan',\n",
    "         'average sentence rank':round(np.mean(manhattan_rank)),\n",
    "         'accuracy [%]':round((manhattan_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)\n",
    "\n",
    "data = {'arithmetics':'mean',\n",
    "         'questions modification':'medium',\n",
    "         'metric':'cosine',\n",
    "         'average sentence rank':round(np.mean(cos_rank)),\n",
    "         'accuracy [%]':round((cos_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd64b7a",
   "metadata": {},
   "source": [
    "## Heavily modified questions - sum arithmetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1494a83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "euclidean_ranks = []\n",
    "manhattan_ranks = []\n",
    "cos_ranks = []\n",
    "\n",
    "euclidean_target_counter = 0\n",
    "manhattan_target_counter = 0\n",
    "cos_target_counter = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(test_questions_number):\n",
    "    \n",
    "    original_question = qm_base[\"original question\"][i]\n",
    "    modified_question = np.reshape(qhm_vectorized_sum[i],(1,-1))\n",
    "    \n",
    "    distances_euclidean, indices_euclidean = nbrs_euclidean_sum.kneighbors(modified_question)\n",
    "    distances_manhattan, indices_manhattan = nbrs_manhattan_sum.kneighbors(modified_question)\n",
    "    distances_cosine, indices_cosine = nbrs_cosine_sum.kneighbors(modified_question)\n",
    "    \n",
    "    nbrs_list_euclidean = qa_base[\"Question\"].iloc[indices_euclidean[0]].tolist()\n",
    "    nbrs_list_manhattan = qa_base[\"Question\"].iloc[indices_manhattan[0]].tolist()\n",
    "    nbrs_list_cosine = qa_base[\"Question\"].iloc[indices_cosine[0]].tolist()\n",
    "    \n",
    "    euclidean_rank = nbrs_list_euclidean.index(original_question)+1\n",
    "    manhattan_rank = nbrs_list_manhattan.index(original_question)+1\n",
    "    cos_rank = nbrs_list_cosine.index(original_question)+1\n",
    "    \n",
    "    euclidean_ranks.append(euclidean_rank)\n",
    "    manhattan_ranks.append(manhattan_rank)\n",
    "    cos_ranks.append(cos_rank)\n",
    "    \n",
    "    if euclidean_rank <= 300:\n",
    "        euclidean_target_counter += 1\n",
    "    if manhattan_rank <= 300:\n",
    "        manhattan_target_counter += 1\n",
    "    if cos_rank <= 300:\n",
    "        cos_target_counter += 1\n",
    "    \n",
    "end = time.time()\n",
    "t = (end-start)/test_questions_number\n",
    "\n",
    "print(\"Heavy modifications - euclidian ranks:\", euclidean_ranks)\n",
    "print(\"Heavy modifications - manhattan ranks:\", manhattan_ranks)\n",
    "print(\"Heavy modifications - cos ranks:\", cos_ranks)\n",
    "\n",
    "data = {'arithmetics':'sum',\n",
    "         'questions modification':'heavy',\n",
    "         'metric':'euclidean',\n",
    "         'average sentence rank':round(np.mean(euclidean_rank)),\n",
    "         'accuracy [%]':round((euclidean_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)\n",
    "\n",
    "data = {'arithmetics':'sum',\n",
    "         'questions modification':'heavy',\n",
    "         'metric':'manhattan',\n",
    "         'average sentence rank':round(np.mean(manhattan_rank)),\n",
    "         'accuracy [%]':round((manhattan_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)\n",
    "\n",
    "data = {'arithmetics':'sum',\n",
    "         'questions modification':'heavy',\n",
    "         'metric':'cosine',\n",
    "         'average sentence rank':round(np.mean(cos_rank)),\n",
    "         'accuracy [%]':round((cos_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8c9c1",
   "metadata": {},
   "source": [
    "## Heavily modified questions - mean arithmetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e55cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "euclidean_ranks = []\n",
    "manhattan_ranks = []\n",
    "cos_ranks = []\n",
    "\n",
    "euclidean_target_counter = 0\n",
    "manhattan_target_counter = 0\n",
    "cos_target_counter = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(test_questions_number):\n",
    "    \n",
    "    original_question = qm_base[\"original question\"][i]\n",
    "    modified_question = np.reshape(qhm_vectorized_mean[i],(1,-1))\n",
    "    \n",
    "    distances_euclidean, indices_euclidean = nbrs_euclidean_mean.kneighbors(modified_question)\n",
    "    distances_manhattan, indices_manhattan = nbrs_manhattan_mean.kneighbors(modified_question)\n",
    "    distances_cosine, indices_cosine = nbrs_cosine_mean.kneighbors(modified_question)\n",
    "    \n",
    "    nbrs_list_euclidean = qa_base[\"Question\"].iloc[indices_euclidean[0]].tolist()\n",
    "    nbrs_list_manhattan = qa_base[\"Question\"].iloc[indices_manhattan[0]].tolist()\n",
    "    nbrs_list_cosine = qa_base[\"Question\"].iloc[indices_cosine[0]].tolist()\n",
    "    \n",
    "    euclidean_rank = nbrs_list_euclidean.index(original_question)+1\n",
    "    manhattan_rank = nbrs_list_manhattan.index(original_question)+1\n",
    "    cos_rank = nbrs_list_cosine.index(original_question)+1\n",
    "    \n",
    "    euclidean_ranks.append(euclidean_rank)\n",
    "    manhattan_ranks.append(manhattan_rank)\n",
    "    cos_ranks.append(cos_rank)\n",
    "    \n",
    "    if euclidean_rank <= 300:\n",
    "        euclidean_target_counter += 1\n",
    "    if manhattan_rank <= 300:\n",
    "        manhattan_target_counter += 1\n",
    "    if cos_rank <= 300:\n",
    "        cos_target_counter += 1\n",
    "    \n",
    "end = time.time()\n",
    "t = (end-start)/test_questions_number\n",
    "\n",
    "print(\"Heavy modifications - euclidian ranks:\", euclidean_ranks)\n",
    "print(\"Heavy modifications - manhattan ranks:\", manhattan_ranks)\n",
    "print(\"Heavy modifications - cos ranks:\", cos_ranks)\n",
    "\n",
    "data = {'arithmetics':'mean',\n",
    "         'questions modification':'heavy',\n",
    "         'metric':'euclidean',\n",
    "         'average sentence rank':round(np.mean(euclidean_rank)),\n",
    "         'accuracy [%]':round((euclidean_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)\n",
    "\n",
    "data = {'arithmetics':'mean',\n",
    "         'questions modification':'heavy',\n",
    "         'metric':'manhattan',\n",
    "         'average sentence rank':round(np.mean(manhattan_rank)),\n",
    "         'accuracy [%]':round((manhattan_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)\n",
    "\n",
    "data = {'arithmetics':'mean',\n",
    "         'questions modification':'heavy',\n",
    "         'metric':'cosine',\n",
    "         'average sentence rank':round(np.mean(cos_rank)),\n",
    "         'accuracy [%]':round((cos_target_counter/test_questions_number)*100,2),\n",
    "         'average execution time [s]':round(t,4)}\n",
    "\n",
    "results = results.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d438e4",
   "metadata": {},
   "source": [
    "## View of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3220a7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.to_csv(\"results - word vectorization - POS.csv\",index=False)\n",
    "\n",
    "results.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0413af8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
